{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3condae788c5fa592f4db3927eca9f2fe371f6",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 10 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "# 손으로 쓴 숫자 데이터 읽기\n",
    "digits=datasets.load_digits()\n",
    "\n",
    "# 이미지를 2행 5열로 표시\n",
    "for label, img in zip(digits.target[:10], digits.images[:10]):\n",
    "    plt.subplot(2, 5, label + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Digit: {0}'.format(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3과 8의 데이터 위치를 구하기\n",
    "flag_3_8=(digits.target == 3) + (digits.target == 8)\n",
    "\n",
    "# 3과 8 이미지와 레이블을 구해서 변수에 저장\n",
    "images = digits.images[flag_3_8]\n",
    "# 357개 , 8행 8열 2차원 \n",
    "\n",
    "labels = digits.target[flag_3_8]\n",
    "\n",
    "# 3과 8이 이미지 데이터를 2차원에서 1차원으로 변환\n",
    "images = images.reshape(images.shape[0], -1)    # -1은 가변적\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, \n",
    "                                                    labels, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=10)\n",
    "# x_train     # 훈련 이미지\n",
    "# x_test      # 테스트 이미지\n",
    "# y_train     # 훈련 라벨\n",
    "# y_test      # 테스트 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "정답률(Accuracy): 0.9629629629629629\n혼돈행렬(Confusion matrix): \n [[51  4]\n [ 0 53]]\n3라벨 적합률(Presision): 1.0\n8라벨 적합률(Presision): 0.9298245614035088\n3라벨 재현율(Recall): 0.9272727272727272\n8라벨 재현율(Recall): 1.0\n3라벨 F값(F-measure): 0.9622641509433962\n8라벨 F값(F-measure): 0.9636363636363636\n"
    }
   ],
   "source": [
    "# 결정 트리 분류기 모델 생성\n",
    "from sklearn import ensemble, tree\n",
    "\n",
    "# 모델 생성 \n",
    "# base_estimator는 약한 학습기를 지정하는 파라미터로 여기서는 결정트리를 지정,\n",
    "# n_estimators는 약한 학습기 갯수를 지정\n",
    "classifier = ensemble.AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=3), n_estimators=20)\n",
    "# 모델 학습\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "predict_label = classifier.predict(x_test)# 예측 라벨값\n",
    "\n",
    "print('정답률(Accuracy):', metrics.accuracy_score(y_test, predict_label))\n",
    "print('혼돈행렬(Confusion matrix): \\n', metrics.confusion_matrix(y_test, predict_label))\n",
    "# pos_label=3 -> 3 라벨의 적합률이 잘나온지\n",
    "print('3라벨 적합률(Presision):', metrics.precision_score(y_test, predict_label, pos_label=3))   \n",
    "print('8라벨 적합률(Presision):', metrics.precision_score(y_test, predict_label, pos_label=8))\n",
    "print('3라벨 재현율(Recall):', metrics.recall_score(y_test, predict_label, pos_label=3))\n",
    "print('8라벨 재현율(Recall):', metrics.recall_score(y_test, predict_label, pos_label=8))\n",
    "print('3라벨 F값(F-measure):', metrics.f1_score(y_test, predict_label, pos_label=3))\n",
    "print('8라벨 F값(F-measure):', metrics.f1_score(y_test, predict_label, pos_label=8))"
   ]
  }
 ]
}