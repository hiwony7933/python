{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3condae788c5fa592f4db3927eca9f2fe371f6",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "df = pd.read_csv('/Users/jw/python/4.Study/data/auto-mpg.csv', header=None)\n",
    "df.columns = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0      130.0\n1      165.0\n2      150.0\n3      150.0\n4      140.0\n       ...  \n393    86.00\n394    52.00\n395    84.00\n396    79.00\n397    82.00\nName: horsepower, Length: 398, dtype: object\n"
    }
   ],
   "source": [
    "print(df['horsepower'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형변환 \n",
    "# df['horsepower'] = df['horsepower'].astype('float')\n",
    "# object 형식을 float로 치환할려고 하려니 아래와 같은 에러가 발생한다. \n",
    "# 데이터중에 ? 가 있나보다.\n",
    "# ValueError: could not convert string to float: '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?인 데이터를 NaN으로 치환하고 NaN인 데이터를 제거 \n",
    "df['horsepower'].replace('?', np.NaN, inplace=True)\n",
    "df.dropna(subset=['horsepower'], inplace=True, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 형변환 \n",
    "df['horsepower'] = df['horsepower'].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[ 46.         107.33333333 168.66666667 230.        ]\n"
    }
   ],
   "source": [
    "# horsepower를 저출력, 보통출력, 고출력으로 구간분할\n",
    "# 범주형 목록을 생성\n",
    "bin_names = ['저출력', '보통출력','고출력']\n",
    "# 3개로 나눌 경계값을 생성\n",
    "count, bin_dividers = np.histogram(df['horsepower'], bins=3)\n",
    "print(bin_dividers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0      보통출력\n1      보통출력\n2      보통출력\n3      보통출력\n4      보통출력\n       ... \n393     저출력\n394     저출력\n395     저출력\n396     저출력\n397     저출력\nName: hp_bin, Length: 392, dtype: category\nCategories (3, object): [저출력 < 보통출력 < 고출력]\n"
    }
   ],
   "source": [
    "# 구간 분할\n",
    "df['hp_bin'] = pd.cut(x=df['horsepower'], bins=bin_dividers, labels=bin_names, include_lowest=True)\n",
    "print(df['hp_bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "hp_bin  저출력  보통출력  고출력\n0         0     1    0\n1         0     1    0\n2         0     1    0\n3         0     1    0\n4         0     1    0\n..      ...   ...  ...\n393       1     0    0\n394       1     0    0\n395       1     0    0\n396       1     0    0\n397       1     0    0\n\n[392 rows x 3 columns]\n"
    }
   ],
   "source": [
    "# hp_bin 을 원핫인코딩 - 3개의 컬럼이 생성되고\n",
    "# 컬럼의 이름은 저출력, 보통출력, 고출력이 된다. \n",
    "# 자신의 값과 일치하는 컬럼에만 1이 되고 나머지 컬럼에는 0이 대입 \n",
    "# 저출력 보통출력 고출력 \n",
    "# 0         1        0\n",
    "# 컬럼이름이 있음\n",
    "dummy = pd.get_dummies(df['hp_bin'])\n",
    "print(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0 1 0]\n [0 1 0]\n [0 1 0]\n ...\n [0 0 1]\n [0 0 1]\n [0 0 1]]\n"
    }
   ],
   "source": [
    "# 사이킷 런을 이용한 원 핫 인코딩\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# 컬럼이름이 없다.\n",
    "# [[0 1 0 ]]\n",
    "one_hot = LabelBinarizer()\n",
    "print(one_hot.fit_transform(df['hp_bin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['고출력' '보통출력' '저출력']\n"
    }
   ],
   "source": [
    "# sort를 해버려서 class가 뭔지 확인을 해야한다. \n",
    "# 데이터를 정렬하기 때문에 순서를 확인해야 한다. \n",
    "print(one_hot.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '고출력' '고출력' '고출력' '고출력' '고출력' '고출력'\n '보통출력' '보통출력' '고출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '보통출력' '저출력' '고출력' '고출력' '고출력' '고출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '보통출력' '고출력' '보통출력' '보통출력' '고출력' '고출력' '고출력' '보통출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '보통출력' '고출력' '보통출력' '보통출력' '보통출력' '고출력' '보통출력' '보통출력'\n '고출력' '저출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '고출력' '보통출력' '보통출력' '보통출력' '보통출력' '고출력' '보통출력'\n '보통출력' '보통출력' '고출력' '고출력' '고출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '보통출력' '보통출력' '고출력' '고출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '보통출력' '고출력' '저출력' '저출력' '저출력' '보통출력' '보통출력' '보통출력' '보통출력' '고출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '보통출력' '보통출력'\n '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '고출력' '보통출력' '보통출력' '보통출력'\n '보통출력' '저출력' '보통출력' '저출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '보통출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '보통출력' '저출력' '보통출력' '보통출력' '고출력' '보통출력' '보통출력' '보통출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력'\n '저출력' '고출력' '고출력' '고출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '보통출력'\n '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '보통출력'\n '보통출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '보통출력' '저출력' '저출력' '저출력'\n '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '보통출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '보통출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '보통출력' '보통출력' '보통출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력' '보통출력' '저출력' '저출력' '보통출력' '저출력' '저출력' '저출력'\n '저출력' '저출력' '저출력' '저출력' '저출력']\n"
    }
   ],
   "source": [
    "print(one_hot.inverse_transform(one_hot.fit_transform(df['hp_bin'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[0 1 1 0 0]\n [0 0 1 1 0]\n [1 0 0 0 1]\n [0 0 0 1 1]]\n['C#' 'C++' 'Java' 'Python' 'R']\n"
    }
   ],
   "source": [
    "# 여러개이 특성을 원 핫 인코딩 \n",
    "# 한개의 데이터가 여러 개의 특성을 갖는 경우 - Tuple, List 등\n",
    "# 문장의 유사도 측정, 상품 추천 할 때 사용 \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "features = [('Java', 'C++'), ('Java', 'Python'), ('C#', 'R'), ('Python', 'R')]\n",
    "one_hot = MultiLabelBinarizer()\n",
    "print(one_hot.fit_transform(features))\n",
    "print(one_hot.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[1 1 1 1 1 0 0 0 0 0 0 1 1 0 2 2 2 2 2 2 2 2 2 1 2 0 0 0 0 2 2 2 2 2 2 2 2\n 1 0 1 1 0 0 0 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 1 1 1 0 1 1 0 2 1 1 1\n 1 1 2 2 2 2 2 2 2 2 0 1 1 1 1 0 1 1 1 0 0 0 2 2 2 2 2 2 1 1 0 0 2 2 2 2 2\n 2 2 2 1 0 2 2 2 1 1 1 1 0 2 2 2 2 2 2 2 2 1 2 1 1 1 1 1 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 0 1 1 1 1 2 1 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2\n 1 1 1 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 1 2 1 1 0 1 1 1 2 2 2 2 2 1 1 1\n 1 1 2 2 2 0 0 0 1 2 2 2 2 2 2 2 2 2 1 1 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 1\n 1 1 1 1 1 2 2 2 2 2 2 2 2 2 1 1 1 2 2 1 2 2 2 1 1 1 1 1 1 1 1 1 2 2 2 2 2\n 1 2 2 2 2 2 2 2 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2\n 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 1 2 2 1 2 2 2 2 2 2 2 2]\n"
    }
   ],
   "source": [
    "# get_dummies는 하나의 특성을 하나의 컬럼으로 생성 \n",
    "# 값의 종류가 15가지이면 15개의 컬럼이 생성\n",
    "# 컬럼을 1개만 만들고 0부터 일련번호 형태로 값을 설정 \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "one_hot = LabelEncoder()\n",
    "print(one_hot.fit_transform(df['hp_bin']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Score\n0    저조\n1    우수\n2    보통\n3    저조\n"
    }
   ],
   "source": [
    "# sklearn 의 인코더들은 문자열을 기준으로 정렬을 한 후 수치를 부여함. \n",
    "# 원하는 수치값으로 부여할수가 없음 \n",
    "# 범주형 데이터에 원하는 수치값을 부여해서 인코딩할 때는 replace 메소드나 OrdinalEncoder 이용 \n",
    "\n",
    "# 이상태에서 인코딩하면 보통->우수->저조 순서입니다.\n",
    "df = pd.DataFrame({'Score':['저조', '우수','보통', '저조']})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Score  encoder\n0    저조        0\n1    우수        2\n2    보통        1\n3    저조        0\n"
    }
   ],
   "source": [
    "mapper = {'저조':0, '보통' :1, '우수':2}\n",
    "# 저조:0, 보통:1, 우수:2\n",
    "df['encoder'] = df['Score'].replace(mapper)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1. 3.]\n [2. 0.]\n [0. 2.]\n [3. 1.]]\n"
    }
   ],
   "source": [
    "# 순서가 있는 범주형 인코딩 \n",
    "from sklearn.preprocessing import  OrdinalEncoder\n",
    "features = np.array([['대한민국', 30], ['미국', 10],['뉴질랜드', 25],['캐나다', 20]])\n",
    "\n",
    "# 각 컬럼의 데이터를 정렬하고 순서대로 가중치를 부여 \n",
    "# 가나다 순, 숫자 \n",
    "encoder = OrdinalEncoder()\n",
    "result = encoder.fit_transform(features)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0. 3.]\n"
    }
   ],
   "source": [
    "# 머신러닝 알고리즘을 이용한 누락된 값 대체\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 훈련할 데이터 \n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "              [1, 1.22, 4.34],\n",
    "              [0, 2.34, 1.98],\n",
    "              [3, -1.19, -0.30]])\n",
    "\n",
    "# NaN을 가진 데이터\n",
    "X_with_nan = np.array([[np.NaN, 0.33, 0.22],\n",
    "                       [np.NaN, -3.22, -1.45]])\n",
    "\n",
    "# 분류기를 생성\n",
    "clf = KNeighborsClassifier(3, weights='distance')\n",
    "\n",
    "# 훈련 모델\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "\n",
    "# 데이터 예측\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:])\n",
    "print(imputed_values)\n",
    "\n",
    "# 갑과의 거리가 짧은 값으로 리턴 "
   ]
  }
 ]
}